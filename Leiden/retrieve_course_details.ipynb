{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "#load course IDs\n",
    "course_ids = pd.read_csv('data/course_IDs.csv')\n",
    "course_ids = course_ids['course_ID'].tolist()\n",
    "course_ids = [str(i) for i in course_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = True\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "course_ids_test = random.sample(course_ids, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(soup, url):\n",
    "    # get the course name\n",
    "    title_article = soup.find('article', class_='content')\n",
    "    year = soup.find('div', class_='edition').text.strip()\n",
    "    \n",
    "    course_title = soup.find('h1').text.strip()\n",
    "\n",
    "    try:\n",
    "        language = soup.find('dt', string='Language')\n",
    "        language = language.find_next_sibling().text.strip()\n",
    "    except:\n",
    "        language = 'None'\n",
    "    \n",
    "    try:\n",
    "        college = soup.find('dt', string='Faculty')\n",
    "        college = college.find_next_sibling().text.strip()\n",
    "    except:\n",
    "        college = 'None'\n",
    "\n",
    "    try:\n",
    "        lecturers = soup.find('dt', string={'Teacher', 'Teachers'})\n",
    "        lecturers = lecturers.find_next_sibling().text.strip()\n",
    "        lecturers = lecturers.split('\\n')\n",
    "    except:\n",
    "        lecturers = 'None'\n",
    "\n",
    "    try:\n",
    "        lecturers_urls = soup.find('dt', string={'Teacher', 'Teachers'})\n",
    "        lecturers_urls_container = lecturers_urls.find_next_sibling()\n",
    "        lecturers_urls = lecturers_urls_container.find_all('a')\n",
    "        #get links\n",
    "        if len(lecturers_urls) == 0:\n",
    "            lecturers_urls = 'None'\n",
    "        else:\n",
    "            lecturers_urls = [i['href'] for i in lecturers_urls]\n",
    "    except:\n",
    "        lecturers_urls = 'None'\n",
    "\n",
    "    try:\n",
    "        programmes_prev = soup.find('h2', string='Part of')\n",
    "        programmes_container = programmes_prev.find_next_sibling('ul')\n",
    "        programmes = programmes_container.find_all('a')\n",
    "        #get links\n",
    "        programmes = [i['href'] for i in programmes]\n",
    "    except:\n",
    "        programmes = 'None'\n",
    "\n",
    "    try:\n",
    "        text_container = soup.find('div', class_='wrapper main clearfix')\n",
    "        text = text_container.find('article', class_='content').text.strip()\n",
    "    except:\n",
    "        text = 'None'\n",
    "\n",
    "    #create dictionary from course details\n",
    "    course_details = {\n",
    "        'url': url,\n",
    "        'year': year,\n",
    "        'course_title': course_title,\n",
    "        'language': language,\n",
    "        'college': college,\n",
    "        'lecturers_urls': lecturers_urls,\n",
    "        'lecturers': lecturers,\n",
    "        'programmes': programmes,\n",
    "        'text': text\n",
    "    }\n",
    "\n",
    "    return course_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71978f24d4e471e8ebdb0874d3213fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://studiegids.universiteitleiden.nl/en/courses/'\n",
    "\n",
    "# create empty df\n",
    "course_details_df = pd.DataFrame(columns=['url', 'year','course_title','language','college','lecturers_urls','lecturers','programmes','text'])\n",
    "\n",
    "# loop over all course IDs\n",
    "for i in tqdm(course_ids_test if TESTING else course_ids):\n",
    "    # get the html code of the course page\n",
    "    url_new = url + i\n",
    "    response = requests.get(url_new)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    course_details = get_details(soup, url_new)\n",
    "    \n",
    "    #append dictionary to df\n",
    "    course_details_df = course_details_df._append(course_details, ignore_index=True)\n",
    "\n",
    "#save df to csv\n",
    "course_details_df.to_csv('data/course_details.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
